%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for 김당찬 at 2023-11-24 11:46:38 +0900 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{pmlr-v37-rezende15,
	abstract = {The choice of the approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.},
	address = {Lille, France},
	author = {Rezende, Danilo and Mohamed, Shakir},
	booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
	editor = {Bach, Francis and Blei, David},
	month = {07--09 Jul},
	pages = {1530--1538},
	pdf = {http://proceedings.mlr.press/v37/rezende15.pdf},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {Variational Inference with Normalizing Flows},
	url = {https://proceedings.mlr.press/v37/rezende15.html},
	volume = {37},
	year = {2015},
	bdsk-url-1 = {https://proceedings.mlr.press/v37/rezende15.html}}

@misc{tomczak2017ccliniaf,
	archiveprefix = {arXiv},
	author = {Jakub M. Tomczak and Max Welling},
	date-modified = {2023-11-24 11:44:47 +0900},
	eprint = {1706.02326},
	primaryclass = {stat.ML},
	title = {Improving Variational Auto-Encoders using convex combination linear Inverse Autoregressive Flow},
	year = {2017}}

@article{wang2017empirical,
	abstract = {We consider linear structural equation models that are associated with mixed graphs. The structural equations in these models only involve observed variables, but their idiosyncratic error terms are allowed to be correlated and non-Gaussian. We propose empirical likelihood procedures for inference and suggest several modifications, including a profile likelihood, in order to improve tractability and performance of the resulting methods. Through simulations, we show that when the error distributions are non-Gaussian, the use of empirical likelihood and the proposed modifications may increase statistical efficiency and improve assessment of significance. Copyright {\copyright} 2017 John Wiley \& Sons, Ltd.},
	author = {Wang, Y. Samuel and Drton, Mathias},
	date-modified = {2023-11-24 11:45:41 +0900},
	doi = {https://doi.org/10.1002/sta4.169},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sta4.169},
	journal = {Stat},
	keywords = {causal inference, empirical likelihood, graphical model, structural equation model},
	number = {1},
	pages = {434-447},
	title = {Empirical likelihood for linear structural equation models with dependent errors},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sta4.169},
	volume = {6},
	year = {2017},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sta4.169},
	bdsk-url-2 = {https://doi.org/10.1002/sta4.169}}

@inproceedings{kingma2016iaf,
	author = {Kingma, Durk P and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
	booktitle = {Advances in Neural Information Processing Systems},
	date-modified = {2023-11-24 11:45:15 +0900},
	editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Improved Variational Inference with Inverse Autoregressive Flow},
	url = {https://proceedings.neurips.cc/paper_files/paper/2016/file/ddeebdeefdb7e7e7a697e1c3e3d8ef54-Paper.pdf},
	volume = {29},
	year = {2016},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2016/file/ddeebdeefdb7e7e7a697e1c3e3d8ef54-Paper.pdf}}

@misc{tomczak2017householder,
	archiveprefix = {arXiv},
	author = {Jakub M. Tomczak and Max Welling},
	date-modified = {2023-11-24 11:44:38 +0900},
	eprint = {1611.09630},
	primaryclass = {cs.LG},
	title = {Improving Variational Auto-Encoders using Householder Flow},
	year = {2017}}

@misc{zhang2019dvae,
	archiveprefix = {arXiv},
	author = {Muhan Zhang and Shali Jiang and Zhicheng Cui and Roman Garnett and Yixin Chen},
	eprint = {1904.11088},
	primaryclass = {cs.LG},
	title = {D-VAE: A Variational Autoencoder for Directed Acyclic Graphs},
	year = {2019}}

@book{pml2Book,
	author = {Kevin P. Murphy},
	publisher = {MIT Press},
	title = {Probabilistic Machine Learning: Advanced Topics},
	url = {http://probml.github.io/book2},
	year = 2023,
	bdsk-url-1 = {http://probml.github.io/book2}}

@misc{rolinek2019variationalpca,
	archiveprefix = {arXiv},
	author = {Michal Rolinek and Dominik Zietlow and Georg Martius},
	date-modified = {2023-11-24 11:46:20 +0900},
	eprint = {1812.06775},
	primaryclass = {cs.LG},
	title = {Variational Autoencoders Pursue PCA Directions (by Accident)},
	year = {2019}}

@misc{frazier2018tutorial,
	archiveprefix = {arXiv},
	author = {Peter I. Frazier},
	eprint = {1807.02811},
	primaryclass = {stat.ML},
	title = {A Tutorial on Bayesian Optimization},
	year = {2018}}

@inproceedings{Yang_2021_CVPR,
	author = {Yang, Mengyue and Liu, Furui and Chen, Zhitang and Shen, Xinwei and Hao, Jianye and Wang, Jun},
	booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	pages = {9593-9602},
	title = {CausalVAE: Disentangled Representation Learning via Neural Structural Causal Models},
	year = {2021}}

@misc{kipf2016variational,
	archiveprefix = {arXiv},
	author = {Thomas N. Kipf and Max Welling},
	eprint = {1611.07308},
	primaryclass = {stat.ML},
	title = {Variational Graph Auto-Encoders},
	year = {2016}}

@misc{burgess2018beta,
	archiveprefix = {arXiv},
	author = {Christopher P. Burgess and Irina Higgins and Arka Pal and Loic Matthey and Nick Watters and Guillaume Desjardins and Alexander Lerchner},
	date-modified = {2023-11-24 11:45:57 +0900},
	eprint = {1804.03599},
	primaryclass = {stat.ML},
	title = {Understanding disentangling in $\beta$-VAE},
	year = {2018}}

@article{mlpsvd,
	abstract = {The multilayer perceptron, when working in auto-association mode, is sometimes considered as an interesting candidate to perform data compression or dimensionality reduction of the feature space in information processing applications. The present paper shows that, for auto-association, the nonlinearities of the hidden units are useless and that the optimal parameter values can be derived directly by purely linear techniques relying on singular value decomposition and low rank matrix approximation, similar in spirit to the well-known Karhunen-Lo{\`e}ve transform. This approach appears thus as an efficient alternative to the general error back-propagation algorithm commonly used for training multilayer perceptrons. Moreover, it also gives a clear interpretation of the r{\^o}le of the different parameters.},
	author = {Bourlard, H. and Kamp, Y.},
	date = {1988/09/01},
	date-added = {2023-10-18 21:02:45 +0900},
	date-modified = {2023-10-18 21:02:45 +0900},
	doi = {10.1007/BF00332918},
	id = {Bourlard1988},
	isbn = {1432-0770},
	journal = {Biological Cybernetics},
	number = {4},
	pages = {291--294},
	title = {Auto-association by multilayer perceptrons and singular value decomposition},
	url = {https://doi.org/10.1007/BF00332918},
	volume = {59},
	year = {1988},
	bdsk-url-1 = {https://doi.org/10.1007/BF00332918}}

@misc{li2020dirichlet,
	archiveprefix = {arXiv},
	author = {Jia Li and Tomasyu Yu and Jiajin Li and Honglei Zhang and Kangfei Zhao and YU Rong and Hong Cheng and Junzhou Huang},
	eprint = {2010.04408},
	primaryclass = {cs.LG},
	title = {Dirichlet Graph Variational Autoencoder},
	year = {2020}}

@article{ChickeringGES,
	abstract = {In this paper we prove the so-called "Meek Conjecture". In particular, we show that if a DAG H is an independence map of another DAG G, then there exists a finite sequence of edge additions and covered edge reversals in G such that (1) after each edge modification H remains an independence map of G and (2) after all modifications G =H. As shown by Meek (1997), this result has an important consequence for Bayesian approaches to learning Bayesian networks from data: in the limit of large sample size, there exists a two-phase greedy search algorithm that---when applied to a particular sparsely-connected search space---provably identifies a perfect map of the generative distribution if that perfect map is a DAG. We provide a new implementation of the search space, using equivalence classes as states, for which all operators used in the greedy search can be scored efficiently using local functions of the nodes in the domain. Finally, using both synthetic and real-world datasets, we demonstrate that the two-phase greedy approach leads to good solutions when learning with finite sample sizes.},
	author = {Chickering, David Maxwell},
	doi = {10.1162/153244303321897717},
	issn = {1532-4435},
	issue_date = {3/1/2003},
	journal = {J. Mach. Learn. Res.},
	month = {mar},
	number = {null},
	numpages = {48},
	pages = {507--554},
	publisher = {JMLR.org},
	title = {Optimal Structure Identification with Greedy Search},
	url = {https://doi.org/10.1162/153244303321897717},
	volume = {3},
	year = {2003},
	bdsk-url-1 = {https://doi.org/10.1162/153244303321897717}}

@article{GhoshalSEM,
	author = {Asish Ghoshal and Jean Honorio},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/GhoshalH17aa.bib},
	eprint = {1707.04673},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:48:07 +0200},
	title = {Learning linear structural equation models in polynomial time and sample complexity},
	url = {http://arxiv.org/abs/1707.04673},
	volume = {abs/1707.04673},
	year = {2017},
	bdsk-url-1 = {http://arxiv.org/abs/1707.04673}}

@article{ChickeringNPhard,
	author = {David Maxwell Chickering and Christopher Meek and David Heckerman},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1212-2468.bib},
	eprint = {1212.2468},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:47:15 +0200},
	title = {Large-Sample Learning of Bayesian Networks is NP-Hard},
	url = {http://arxiv.org/abs/1212.2468},
	volume = {abs/1212.2468},
	year = {2012},
	bdsk-url-1 = {http://arxiv.org/abs/1212.2468}}

@misc{zheng2018dags,
	archiveprefix = {arXiv},
	author = {Xun Zheng and Bryon Aragam and Pradeep Ravikumar and Eric P. Xing},
	eprint = {1803.01422},
	primaryclass = {stat.ML},
	title = {DAGs with NO TEARS: Continuous Optimization for Structure Learning},
	year = {2018}}

@article{yu2019daggnn,
	archiveprefix = {arXiv},
	author = {Yue Yu and Jie Chen and Tian Gao and Mo Yu},
	eprint = {1904.10098},
	primaryclass = {cs.LG},
	title = {DAG-GNN: DAG Structure Learning with Graph Neural Networks},
	year = {2019}}

@book{Spirtes2000,
	added-at = {2009-09-12T19:19:34.000+0200},
	author = {Spirtes, P. and Glymour, C. and Scheines, R.},
	biburl = {https://www.bibsonomy.org/bibtex/2e2b107e8fd3469c8b0e944ca37a559f3/mozaher},
	edition = {2nd},
	interhash = {559e17fcd12a76214629ba6c4efe3f9a},
	intrahash = {e2b107e8fd3469c8b0e944ca37a559f3},
	keywords = {imported},
	owner = {Mozaherul Hoque},
	publisher = {MIT press},
	review = {PC algorithm},
	timestamp = {2009-09-12T19:19:43.000+0200},
	title = {Causation, Prediction, and Search},
	year = 2000}

@article{kingma2013auto,
	author = {Kingma, Diederik P and Welling, Max},
	journal = {arXiv preprint arXiv:1312.6114},
	title = {Auto-encoding variational bayes},
	year = {2013}}

@misc{zhang2018sentencestate,
	archiveprefix = {arXiv},
	author = {Yue Zhang and Qi Liu and Linfeng Song},
	eprint = {1805.02474},
	primaryclass = {cs.CL},
	title = {Sentence-State LSTM for Text Representation},
	year = {2018}}

@misc{zhang2020document,
	archiveprefix = {arXiv},
	author = {Yufeng Zhang and Xueli Yu and Zeyu Cui and Shu Wu and Zhongzhen Wen and Liang Wang},
	eprint = {2004.13826},
	primaryclass = {cs.CL},
	title = {Every Document Owns Its Structure: Inductive Text Classification via Graph Neural Networks},
	year = {2020}}

@misc{marcheggiani2017encoding,
	archiveprefix = {arXiv},
	author = {Diego Marcheggiani and Ivan Titov},
	eprint = {1703.04826},
	primaryclass = {cs.CL},
	title = {Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling},
	year = {2017}}

@misc{beck2018graphtosequence,
	archiveprefix = {arXiv},
	author = {Daniel Beck and Gholamreza Haffari and Trevor Cohn},
	eprint = {1806.09835},
	primaryclass = {cs.CL},
	title = {Graph-to-Sequence Learning using Gated Graph Neural Networks},
	year = {2018}}

@misc{schlichtkrull2017modeling,
	archiveprefix = {arXiv},
	author = {Michael Schlichtkrull and Thomas N. Kipf and Peter Bloem and Rianne van den Berg and Ivan Titov and Max Welling},
	eprint = {1703.06103},
	primaryclass = {stat.ML},
	title = {Modeling Relational Data with Graph Convolutional Networks},
	year = {2017}}

@misc{peng2017crosssentence,
	archiveprefix = {arXiv},
	author = {Nanyun Peng and Hoifung Poon and Chris Quirk and Kristina Toutanova and Wen-tau Yih},
	eprint = {1708.03743},
	primaryclass = {cs.CL},
	title = {Cross-Sentence N-ary Relation Extraction with Graph LSTMs},
	year = {2017}}

@inproceedings{zhao2020vaeforsparse,
	abstract = {Many applications, such as text modelling, high-throughput sequencing, and recommender systems, require analysing sparse, high-dimensional, and overdispersed discrete (count or binary) data. Recent deep probabilistic models based on variational autoencoders (VAE) have shown promising results on discrete data but may have inferior modelling performance due to the insufficient capability in modelling overdispersion and model misspecification. To address these issues, we develop a VAE-based framework using the negative binomial distribution as the data distribution. We also provide an analysis of its properties vis-{\`a}-vis other models. We conduct extensive experiments on three problems from discrete data analysis: text analysis/topic modelling, collaborative filtering, and multi-label learning. Our models outperform state-of-the-art approaches on these problems, while also capturing the phenomenon of overdispersion more effectively.},
	author = {Zhao, He and Rai, Piyush and Du, Lan and Buntine, Wray and Phung, Dinh and Zhou, Mingyuan},
	booktitle = {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
	date-modified = {2023-11-24 11:46:15 +0900},
	editor = {Chiappa, Silvia and Calandra, Roberto},
	month = {26--28 Aug},
	pages = {1684--1694},
	pdf = {http://proceedings.mlr.press/v108/zhao20c/zhao20c.pdf},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {Variational Autoencoders for Sparse and Overdispersed Discrete Data},
	url = {https://proceedings.mlr.press/v108/zhao20c.html},
	volume = {108},
	year = {2020},
	bdsk-url-1 = {https://proceedings.mlr.press/v108/zhao20c.html}}

@article{epvae,
	author = {So, Jonathan and Townsend, James and Gaujac, Benoit},
	journal = {1st Symposium on Advances in Approximate Bayesian Inference},
	title = {EP Structured Variational Autoencoders},
	year = {2018}}

@article{wuetal2011,
	author = {Wu, Jiangning and Xuan, Zhaoguo and Pan, Donghua},
	journal = {International Journal of Innovative Computing, Information and Control},
	month = {05},
	title = {Enhancing text representation for classification tasks with semantic graph structures},
	volume = {7},
	year = {2011}}

@article{CLOUGH2016235,
	abstract = {Citation networks represent the flow of information between agents. They are constrained in time and so form directed acyclic graphs which have a causal structure. Here we provide novel quantitative methods to characterise that structure by adapting methods used in the causal set approach to quantum gravity by considering the networks to be embedded in a Minkowski spacetime and measuring its dimension using Myrheim--Meyer and Midpoint-scaling estimates. We illustrate these methods on citation networks from the arXiv, supreme court judgements from the USA, and patents and find that otherwise similar citation networks have measurably different dimensions. We suggest that these differences can be interpreted in terms of the level of diversity or narrowness in citation behaviour.},
	author = {James R. Clough and Tim S. Evans},
	doi = {https://doi.org/10.1016/j.physa.2015.12.053},
	issn = {0378-4371},
	journal = {Physica A: Statistical Mechanics and its Applications},
	keywords = {Citation network, Directed acyclic graph, Minkowski space, Dimension, Causal set, Network geometry},
	pages = {235-247},
	title = {What is the dimension of citation space?},
	url = {https://www.sciencedirect.com/science/article/pii/S037843711501081X},
	volume = {448},
	year = {2016},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S037843711501081X},
	bdsk-url-2 = {https://doi.org/10.1016/j.physa.2015.12.053}}

@article{erdds1959random,
	author = {ERDdS, P and R\&wi, A},
	journal = {Publ. math. debrecen},
	number = {290-297},
	pages = {18},
	title = {On random graphs I},
	volume = {6},
	year = {1959}}

@misc{reparametrization,
	archiveprefix = {arXiv},
	author = {Michael Figurnov and Shakir Mohamed and Andriy Mnih},
	eprint = {1805.08498},
	primaryclass = {cs.LG},
	title = {Implicit Reparameterization Gradients},
	year = {2019}}
