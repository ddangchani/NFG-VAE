%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for 김당찬 at 2023-10-19 20:31:54 +0900 


%% Saved with string encoding Unicode (UTF-8) 



@misc{zhang2019dvae,
	archiveprefix = {arXiv},
	author = {Muhan Zhang and Shali Jiang and Zhicheng Cui and Roman Garnett and Yixin Chen},
	eprint = {1904.11088},
	primaryclass = {cs.LG},
	title = {D-VAE: A Variational Autoencoder for Directed Acyclic Graphs},
	year = {2019}}

@book{pml2Book,
	author = {Kevin P. Murphy},
	publisher = {MIT Press},
	title = {Probabilistic Machine Learning: Advanced Topics},
	url = {http://probml.github.io/book2},
	year = 2023,
	bdsk-url-1 = {http://probml.github.io/book2}}

@misc{rolinek2019variational,
	archiveprefix = {arXiv},
	author = {Michal Rolinek and Dominik Zietlow and Georg Martius},
	eprint = {1812.06775},
	primaryclass = {cs.LG},
	title = {Variational Autoencoders Pursue PCA Directions (by Accident)},
	year = {2019}}

@misc{frazier2018tutorial,
	archiveprefix = {arXiv},
	author = {Peter I. Frazier},
	eprint = {1807.02811},
	primaryclass = {stat.ML},
	title = {A Tutorial on Bayesian Optimization},
	year = {2018}}

@inproceedings{Yang_2021_CVPR,
	author = {Yang, Mengyue and Liu, Furui and Chen, Zhitang and Shen, Xinwei and Hao, Jianye and Wang, Jun},
	booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	pages = {9593-9602},
	title = {CausalVAE: Disentangled Representation Learning via Neural Structural Causal Models},
	year = {2021}}

@misc{kipf2016variational,
	archiveprefix = {arXiv},
	author = {Thomas N. Kipf and Max Welling},
	eprint = {1611.07308},
	primaryclass = {stat.ML},
	title = {Variational Graph Auto-Encoders},
	year = {2016}}

@misc{burgess2018understanding,
	archiveprefix = {arXiv},
	author = {Christopher P. Burgess and Irina Higgins and Arka Pal and Loic Matthey and Nick Watters and Guillaume Desjardins and Alexander Lerchner},
	eprint = {1804.03599},
	primaryclass = {stat.ML},
	title = {Understanding disentangling in $\beta$-VAE},
	year = {2018}}

@article{mlpsvd,
	abstract = {The multilayer perceptron, when working in auto-association mode, is sometimes considered as an interesting candidate to perform data compression or dimensionality reduction of the feature space in information processing applications. The present paper shows that, for auto-association, the nonlinearities of the hidden units are useless and that the optimal parameter values can be derived directly by purely linear techniques relying on singular value decomposition and low rank matrix approximation, similar in spirit to the well-known Karhunen-Lo{\`e}ve transform. This approach appears thus as an efficient alternative to the general error back-propagation algorithm commonly used for training multilayer perceptrons. Moreover, it also gives a clear interpretation of the r{\^o}le of the different parameters.},
	author = {Bourlard, H. and Kamp, Y.},
	date = {1988/09/01},
	date-added = {2023-10-18 21:02:45 +0900},
	date-modified = {2023-10-18 21:02:45 +0900},
	doi = {10.1007/BF00332918},
	id = {Bourlard1988},
	isbn = {1432-0770},
	journal = {Biological Cybernetics},
	number = {4},
	pages = {291--294},
	title = {Auto-association by multilayer perceptrons and singular value decomposition},
	url = {https://doi.org/10.1007/BF00332918},
	volume = {59},
	year = {1988},
	bdsk-url-1 = {https://doi.org/10.1007/BF00332918}}

@misc{li2020dirichlet,
	archiveprefix = {arXiv},
	author = {Jia Li and Tomasyu Yu and Jiajin Li and Honglei Zhang and Kangfei Zhao and YU Rong and Hong Cheng and Junzhou Huang},
	eprint = {2010.04408},
	primaryclass = {cs.LG},
	title = {Dirichlet Graph Variational Autoencoder},
	year = {2020}}

@article{ChickeringGES,
	abstract = {In this paper we prove the so-called "Meek Conjecture". In particular, we show that if a DAG H is an independence map of another DAG G, then there exists a finite sequence of edge additions and covered edge reversals in G such that (1) after each edge modification H remains an independence map of G and (2) after all modifications G =H. As shown by Meek (1997), this result has an important consequence for Bayesian approaches to learning Bayesian networks from data: in the limit of large sample size, there exists a two-phase greedy search algorithm that---when applied to a particular sparsely-connected search space---provably identifies a perfect map of the generative distribution if that perfect map is a DAG. We provide a new implementation of the search space, using equivalence classes as states, for which all operators used in the greedy search can be scored efficiently using local functions of the nodes in the domain. Finally, using both synthetic and real-world datasets, we demonstrate that the two-phase greedy approach leads to good solutions when learning with finite sample sizes.},
	author = {Chickering, David Maxwell},
	doi = {10.1162/153244303321897717},
	issn = {1532-4435},
	issue_date = {3/1/2003},
	journal = {J. Mach. Learn. Res.},
	month = {mar},
	number = {null},
	numpages = {48},
	pages = {507--554},
	publisher = {JMLR.org},
	title = {Optimal Structure Identification with Greedy Search},
	url = {https://doi.org/10.1162/153244303321897717},
	volume = {3},
	year = {2003},
	bdsk-url-1 = {https://doi.org/10.1162/153244303321897717}}

@article{GhoshalSEM,
	author = {Asish Ghoshal and Jean Honorio},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/GhoshalH17aa.bib},
	eprint = {1707.04673},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:48:07 +0200},
	title = {Learning linear structural equation models in polynomial time and sample complexity},
	url = {http://arxiv.org/abs/1707.04673},
	volume = {abs/1707.04673},
	year = {2017},
	bdsk-url-1 = {http://arxiv.org/abs/1707.04673}}

@article{ChickeringNPhard,
	author = {David Maxwell Chickering and Christopher Meek and David Heckerman},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1212-2468.bib},
	eprint = {1212.2468},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:47:15 +0200},
	title = {Large-Sample Learning of Bayesian Networks is NP-Hard},
	url = {http://arxiv.org/abs/1212.2468},
	volume = {abs/1212.2468},
	year = {2012},
	bdsk-url-1 = {http://arxiv.org/abs/1212.2468}}

@misc{zheng2018dags,
	archiveprefix = {arXiv},
	author = {Xun Zheng and Bryon Aragam and Pradeep Ravikumar and Eric P. Xing},
	eprint = {1803.01422},
	primaryclass = {stat.ML},
	title = {DAGs with NO TEARS: Continuous Optimization for Structure Learning},
	year = {2018}}

@article{yu2019daggnn,
	archiveprefix = {arXiv},
	author = {Yue Yu and Jie Chen and Tian Gao and Mo Yu},
	eprint = {1904.10098},
	primaryclass = {cs.LG},
	title = {DAG-GNN: DAG Structure Learning with Graph Neural Networks},
	year = {2019}}

@book{Spirtes2000,
	added-at = {2009-09-12T19:19:34.000+0200},
	author = {Spirtes, P. and Glymour, C. and Scheines, R.},
	biburl = {https://www.bibsonomy.org/bibtex/2e2b107e8fd3469c8b0e944ca37a559f3/mozaher},
	edition = {2nd},
	interhash = {559e17fcd12a76214629ba6c4efe3f9a},
	intrahash = {e2b107e8fd3469c8b0e944ca37a559f3},
	keywords = {imported},
	owner = {Mozaherul Hoque},
	publisher = {MIT press},
	review = {PC algorithm},
	timestamp = {2009-09-12T19:19:43.000+0200},
	title = {Causation, Prediction, and Search},
	year = 2000}

@article{kingma2013auto,
	title={Auto-encoding variational bayes},
	author={Kingma, Diederik P and Welling, Max},
	journal={arXiv preprint arXiv:1312.6114},
	year={2013}
  }

  @misc{zhang2018sentencestate,
      title={Sentence-State LSTM for Text Representation}, 
      author={Yue Zhang and Qi Liu and Linfeng Song},
      year={2018},
      eprint={1805.02474},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zhang2020document,
      title={Every Document Owns Its Structure: Inductive Text Classification via Graph Neural Networks}, 
      author={Yufeng Zhang and Xueli Yu and Zeyu Cui and Shu Wu and Zhongzhen Wen and Liang Wang},
      year={2020},
      eprint={2004.13826},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{marcheggiani2017encoding,
      title={Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling}, 
      author={Diego Marcheggiani and Ivan Titov},
      year={2017},
      eprint={1703.04826},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{beck2018graphtosequence,
      title={Graph-to-Sequence Learning using Gated Graph Neural Networks}, 
      author={Daniel Beck and Gholamreza Haffari and Trevor Cohn},
      year={2018},
      eprint={1806.09835},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{schlichtkrull2017modeling,
      title={Modeling Relational Data with Graph Convolutional Networks}, 
      author={Michael Schlichtkrull and Thomas N. Kipf and Peter Bloem and Rianne van den Berg and Ivan Titov and Max Welling},
      year={2017},
      eprint={1703.06103},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{peng2017crosssentence,
      title={Cross-Sentence N-ary Relation Extraction with Graph LSTMs}, 
      author={Nanyun Peng and Hoifung Poon and Chris Quirk and Kristina Toutanova and Wen-tau Yih},
      year={2017},
      eprint={1708.03743},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@InProceedings{pmlr-v108-zhao20c,
  title = 	 {Variational Autoencoders for Sparse and Overdispersed Discrete Data},
  author =       {Zhao, He and Rai, Piyush and Du, Lan and Buntine, Wray and Phung, Dinh and Zhou, Mingyuan},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1684--1694},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v108/zhao20c/zhao20c.pdf},
  url = 	 {https://proceedings.mlr.press/v108/zhao20c.html},
  abstract = 	 {Many applications, such as text modelling, high-throughput sequencing, and recommender systems, require analysing sparse, high-dimensional, and overdispersed discrete (count or binary) data. Recent deep probabilistic models based on variational autoencoders (VAE) have shown promising results on discrete data but may have inferior modelling performance due to the insufficient capability in modelling overdispersion and model misspecification. To address these issues, we develop a VAE-based framework using the negative binomial distribution as the data distribution. We also provide an analysis of its properties vis-à-vis other models. We conduct extensive experiments on three problems from discrete data analysis: text analysis/topic modelling, collaborative filtering, and multi-label learning. Our models outperform state-of-the-art approaches on these problems, while also capturing the phenomenon of overdispersion more effectively.}
}


@article{epvae,
  title={EP Structured Variational Autoencoders},
  author={So, Jonathan and Townsend, James and Gaujac, Benoit},
year = {2018},
journal= {1st Symposium on Advances in Approximate Bayesian Inference}
}

@article{wuetal2011,
author = {Wu, Jiangning and Xuan, Zhaoguo and Pan, Donghua},
year = {2011},
month = {05},
pages = {},
title = {Enhancing text representation for classification tasks with semantic graph structures},
volume = {7},
journal = {International Journal of Innovative Computing, Information and Control}
}


@article{CLOUGH2016235,
	abstract = {Citation networks represent the flow of information between agents. They are constrained in time and so form directed acyclic graphs which have a causal structure. Here we provide novel quantitative methods to characterise that structure by adapting methods used in the causal set approach to quantum gravity by considering the networks to be embedded in a Minkowski spacetime and measuring its dimension using Myrheim--Meyer and Midpoint-scaling estimates. We illustrate these methods on citation networks from the arXiv, supreme court judgements from the USA, and patents and find that otherwise similar citation networks have measurably different dimensions. We suggest that these differences can be interpreted in terms of the level of diversity or narrowness in citation behaviour.},
	author = {James R. Clough and Tim S. Evans},
	doi = {https://doi.org/10.1016/j.physa.2015.12.053},
	issn = {0378-4371},
	journal = {Physica A: Statistical Mechanics and its Applications},
	keywords = {Citation network, Directed acyclic graph, Minkowski space, Dimension, Causal set, Network geometry},
	pages = {235-247},
	title = {What is the dimension of citation space?},
	url = {https://www.sciencedirect.com/science/article/pii/S037843711501081X},
	volume = {448},
	year = {2016},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S037843711501081X},
	bdsk-url-2 = {https://doi.org/10.1016/j.physa.2015.12.053}}

@article{erdds1959random,
	title={On random graphs I},
	author={ERDdS, P and R\&wi, A},
	journal={Publ. math. debrecen},
	volume={6},
	number={290-297},
	pages={18},
	year={1959}
  }

@misc{reparametrization,
      title={Implicit Reparameterization Gradients}, 
      author={Michael Figurnov and Shakir Mohamed and Andriy Mnih},
      year={2019},
      eprint={1805.08498},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}